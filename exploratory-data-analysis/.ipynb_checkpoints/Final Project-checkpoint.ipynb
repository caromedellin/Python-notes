{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Congress Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>firstname</th>\n",
       "      <th>middlename</th>\n",
       "      <th>lastname</th>\n",
       "      <th>name_suffix</th>\n",
       "      <th>nickname</th>\n",
       "      <th>party</th>\n",
       "      <th>state</th>\n",
       "      <th>district</th>\n",
       "      <th>in_office</th>\n",
       "      <th>...</th>\n",
       "      <th>govtrack_id</th>\n",
       "      <th>crp_id</th>\n",
       "      <th>twitter_id</th>\n",
       "      <th>congresspedia_url</th>\n",
       "      <th>youtube_url</th>\n",
       "      <th>facebook_id</th>\n",
       "      <th>official_rss</th>\n",
       "      <th>senate_class</th>\n",
       "      <th>birthdate</th>\n",
       "      <th>oc_email</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rep</td>\n",
       "      <td>Neil</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Abercrombie</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>D</td>\n",
       "      <td>HI</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>400001</td>\n",
       "      <td>N00007665</td>\n",
       "      <td>neilabercrombie</td>\n",
       "      <td>http://www.opencongress.org/wiki/Neil_Abercrombie</td>\n",
       "      <td>http://youtube.com/hawaiirep1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1938-06-26</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rep</td>\n",
       "      <td>Gary</td>\n",
       "      <td>L.</td>\n",
       "      <td>Ackerman</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>D</td>\n",
       "      <td>NY</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>400003</td>\n",
       "      <td>N00001143</td>\n",
       "      <td>repgaryackerman</td>\n",
       "      <td>http://www.opencongress.org/wiki/Gary_Ackerman</td>\n",
       "      <td>http://youtube.com/RepAckerman</td>\n",
       "      <td>RepAcherman</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1942-11-19</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rep</td>\n",
       "      <td>Robert</td>\n",
       "      <td>B.</td>\n",
       "      <td>Aderholt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>R</td>\n",
       "      <td>AL</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>400004</td>\n",
       "      <td>N00003028</td>\n",
       "      <td>Robert_Aderholt</td>\n",
       "      <td>http://www.opencongress.org/wiki/Robert_Aderholt</td>\n",
       "      <td>http://youtube.com/RobertAderholt</td>\n",
       "      <td>19787529402</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1965-07-22</td>\n",
       "      <td>Rep.Aderholt@opencongress.org</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sen</td>\n",
       "      <td>Daniel</td>\n",
       "      <td>Kahikina</td>\n",
       "      <td>Akaka</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>D</td>\n",
       "      <td>HI</td>\n",
       "      <td>Junior Seat</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>300001</td>\n",
       "      <td>N00007653</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www.opencongress.org/wiki/Daniel_Akaka</td>\n",
       "      <td>http://youtube.com/senatorakaka</td>\n",
       "      <td>danielakaka</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I</td>\n",
       "      <td>1924-09-11</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sen</td>\n",
       "      <td>Wayne</td>\n",
       "      <td>A.</td>\n",
       "      <td>Allard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>R</td>\n",
       "      <td>CO</td>\n",
       "      <td>Senior Seat</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>300003</td>\n",
       "      <td>N00009082</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www.opencongress.org/wiki/Wayne_Allard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>II</td>\n",
       "      <td>1943-12-02</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  title firstname middlename     lastname name_suffix nickname party state  \\\n",
       "0   Rep      Neil        NaN  Abercrombie         NaN      NaN     D    HI   \n",
       "1   Rep      Gary         L.     Ackerman         NaN      NaN     D    NY   \n",
       "2   Rep    Robert         B.     Aderholt         NaN      NaN     R    AL   \n",
       "3   Sen    Daniel   Kahikina        Akaka         NaN      NaN     D    HI   \n",
       "4   Sen     Wayne         A.       Allard         NaN      NaN     R    CO   \n",
       "\n",
       "      district  in_office              ...               govtrack_id  \\\n",
       "0            1          0              ...                    400001   \n",
       "1            5          0              ...                    400003   \n",
       "2            4          1              ...                    400004   \n",
       "3  Junior Seat          0              ...                    300001   \n",
       "4  Senior Seat          0              ...                    300003   \n",
       "\n",
       "      crp_id       twitter_id  \\\n",
       "0  N00007665  neilabercrombie   \n",
       "1  N00001143  repgaryackerman   \n",
       "2  N00003028  Robert_Aderholt   \n",
       "3  N00007653              NaN   \n",
       "4  N00009082              NaN   \n",
       "\n",
       "                                   congresspedia_url  \\\n",
       "0  http://www.opencongress.org/wiki/Neil_Abercrombie   \n",
       "1     http://www.opencongress.org/wiki/Gary_Ackerman   \n",
       "2   http://www.opencongress.org/wiki/Robert_Aderholt   \n",
       "3      http://www.opencongress.org/wiki/Daniel_Akaka   \n",
       "4      http://www.opencongress.org/wiki/Wayne_Allard   \n",
       "\n",
       "                         youtube_url  facebook_id official_rss  senate_class  \\\n",
       "0      http://youtube.com/hawaiirep1          NaN          NaN           NaN   \n",
       "1     http://youtube.com/RepAckerman  RepAcherman          NaN           NaN   \n",
       "2  http://youtube.com/RobertAderholt  19787529402          NaN           NaN   \n",
       "3    http://youtube.com/senatorakaka  danielakaka          NaN             I   \n",
       "4                                NaN          NaN          NaN            II   \n",
       "\n",
       "    birthdate                       oc_email  \n",
       "0  1938-06-26                            NaN  \n",
       "1  1942-11-19                            NaN  \n",
       "2  1965-07-22  Rep.Aderholt@opencongress.org  \n",
       "3  1924-09-11                            NaN  \n",
       "4  1943-12-02                            NaN  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "congress_words = pd.read_csv(\"../data/legislators.csv\")\n",
    "congress_words = pd.DataFrame(congress_words)\n",
    "congress_words.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['title',\n",
       " 'firstname',\n",
       " 'middlename',\n",
       " 'lastname',\n",
       " 'name_suffix',\n",
       " 'nickname',\n",
       " 'party',\n",
       " 'state',\n",
       " 'district',\n",
       " 'in_office',\n",
       " 'gender',\n",
       " 'phone',\n",
       " 'fax',\n",
       " 'website',\n",
       " 'webform',\n",
       " 'congress_office',\n",
       " 'bioguide_id',\n",
       " 'votesmart_id',\n",
       " 'fec_id',\n",
       " 'govtrack_id',\n",
       " 'crp_id',\n",
       " 'twitter_id',\n",
       " 'congresspedia_url',\n",
       " 'youtube_url',\n",
       " 'facebook_id',\n",
       " 'official_rss',\n",
       " 'senate_class',\n",
       " 'birthdate',\n",
       " 'oc_email']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "congress_words.columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API call\n",
    "I used the bioGuide id to retrive the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A000014', 'A000022', 'A000055', 'A000069', 'A000109', 'A000210', 'A000357', 'A000358', 'A000360', 'A000361']\n"
     ]
    }
   ],
   "source": [
    "l_bioGuides = congress_words.bioguide_id.tolist()\n",
    "print l_bioGuides[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### API call method it can be tweeked to scrape other data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from urllib2 import Request, urlopen\n",
    "import json\n",
    "from pandas.io.json import json_normalize\n",
    "def requestWords( id ):\n",
    "\n",
    "    id = str(id)\n",
    "    url = \"http://capitolwords.org/api/1/phrases.json?entity_type=legislator&entity_value=\"+id+\"&apikey=0bf8e7eb6ce146f48217bfee767c998d\"\n",
    "    request=Request(url)\n",
    "    response = urlopen(request)\n",
    "    contents = response.read()\n",
    "    len(contents)\n",
    "    if len(contents) > 2:\n",
    "        data = json.loads(contents)\n",
    "        words = json_normalize(data)\n",
    "        list_of_words = words.ngram.tolist()\n",
    "        string_of_words =\"|\".join(list_of_words)\n",
    "        return string_of_words\n",
    "    else:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "congress_words['favorite_words'] = congress_words.apply(lambda row: requestWords(row['bioguide_id']),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     hawaiian|hawaii|hawaiians|hawaii's|kalaupapa|e...\n",
       "1     queens|rabbi|jewish|bayside|flushing|nassau|br...\n",
       "2     aderholt|requesting|irons|huntsville|alabama|r...\n",
       "3     hawaii's|hawaii|hawaiians|hawaiian|dsh|va|fas|...\n",
       "4     colorado|flats|missile|rocky|colorado's|denver...\n",
       "5     camden|gloucester|cyprus|rutgers|opic|jersey|p...\n",
       "6     mercury|maine|prescription|pharmaceutical|drug...\n",
       "7     freddie|morgenthau|fannie|you've|pilgrims|mayf...\n",
       "8     tennesseans|carbon-free|tennessee|electricity|...\n",
       "9     rodney|baton|rouge|lsu|louisiana|la|ruston|req...\n",
       "10    murphy|drill|pittsburgh|altmire|sbir|oil|anwr|...\n",
       "11    upstate|herkimer|utica|tay-sachs|suny|cybersec...\n",
       "12    nj|2009|objection|army|minutes|recognized|6|se...\n",
       "13    fairborn|ohio's|xenia|gire|wright-patterson|wa...\n",
       "14    endeavour|skyler|meanings|shuttle|eagle|scout|...\n",
       "15    foia|8015|aumf|government-set|davis-bacon|1034...\n",
       "16    hampshire|guantanamo|timberland|gitmo|detainin...\n",
       "17                                                  NaN\n",
       "18    alean|brock|gantt|anderton|calvin's|sickle|cal...\n",
       "19                                                  NaN\n",
       "Name: favorite_words, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "congress_words.favorite_words.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean responses that where null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "congress_words = congress_words[congress_words.favorite_words.notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of legislators with word record: 763\n"
     ]
    }
   ],
   "source": [
    "print \"Number of legislators with word record:\", len(congress_words.favorite_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build words matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   $0  $1  $1.50  $10  $100  $1000  $100000  $1000000  $10638425746293  $107  \\\n",
      "0   0   0      0    0     0      0        0         0                0     0   \n",
      "1   0   0      0    0     0      0        0         0                0     0   \n",
      "2   0   0      0    0     0      0        0         0                0     0   \n",
      "\n",
      "   ...   ziegler  zimbabwe  zimmer  zinc  zion  zoberman  zone  zones  zoo  \\\n",
      "0  ...         0         0       0     0     0         0     0      0    0   \n",
      "1  ...         0         0       0     0     0         0     0      0    0   \n",
      "2  ...         0         0       0     0     0         0     0      0    0   \n",
      "\n",
      "   zuni  \n",
      "0     0  \n",
      "1     0  \n",
      "2     0  \n",
      "\n",
      "[3 rows x 14420 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index([u'$0', u'$1', u'$1.50', u'$10', u'$100', u'$1000', u'$100000',\n",
       "       u'$1000000', u'$10638425746293', u'$107', u'$12', u'$120', u'$12000',\n",
       "       u'$13', u'$1300', u'$139', u'$14', u'$1400', u'$15', u'$1500',\n",
       "       u'$150000', u'$1500000', u'$159', u'$1600', u'$17', u'$170', u'$18',\n",
       "       u'$186', u'$19', u'$191', u'$2', u'$2.33', u'$200', u'$2000',\n",
       "       u'$200000', u'$2000000', u'$21', u'$23', u'$23000', u'$236', u'$240',\n",
       "       u'$25', u'$250', u'$250000', u'$2500000', u'$270', u'$27000', u'$290',\n",
       "       u'$29000', u'$3', u'$300', u'$3000', u'$30000', u'$300000', u'$30500',\n",
       "       u'$310', u'$319', u'$3300', u'$35', u'$350', u'$35000', u'$350000',\n",
       "       u'$38', u'$4', u'$4.50', u'$400', u'$400000', u'$45', u'$46', u'$464',\n",
       "       u'$5', u'$50', u'$500', u'$5000', u'$50000', u'$500000', u'$5100000',\n",
       "       u'$58', u'$58000', u'$6', u'$60', u'$600', u'$600000', u'$6000000',\n",
       "       u'$61', u'$683', u'$700', u'$713', u'$730', u'$750', u'$750000',\n",
       "       u'$760', u'$787', u'$8', u'$80', u'$800', u'$81', u'$87', u'$90',\n",
       "       u'$900'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "favorite_words = congress_words.favorite_words.str.get_dummies(sep = \"|\")\n",
    "print favorite_words.head(3)\n",
    "favorite_words.columns[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(763, 14420)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "favorite_words.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem: a lot of numbers!!!!\n",
    "Live API so I can't hard code where the word columns start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'944', u'95', u'952', u'953', u'96', u'964', u'97', u'98', u'9800',\n",
       "       u'9896', u'990', u'991', u'9946', u'999', u'9:30', u'?', u'a', u'a&m',\n",
       "       u'a-plus', u'a.', u'a.d.', u'a.m.', u'a.m.e.', u'aaa', u'aacute',\n",
       "       u'aahsa', u'aamodt', u'aana', u'aapg', u'aapi', u'aapis', u'aaron',\n",
       "       u'aarp', u'abandon', u'abandoned', u'abaya', u'abbas', u'abbas's',\n",
       "       u'abbeville', u'abby'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "favorite_words.columns[760:800]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some of the words in it [u'abducted', u'abduction', u'abductions', u'abdullah', u'abel', u'abercrombie', u'aberdeen', u'abernathy', u'abilene', u'abilities', u'ability', u'abilityone', u'abington', u'able', u'able-bodied', u'abm', u'aboard', u'abolitionist', u'abortion', u'abortionist', u'abortions', u'about', u'abraham', u'abscissa', u'absence', u'absent', u'absentee', u'absolutely', u'abstinence', u'absurd', u'abu', u'abu-jamal', u'abundance', u'abundant', u'abuse', u'abused', u'abuses', u'abusive', u'aca', u'acacia', u'academic', u'academics', u'academies', u'academy', u'acadiana', u'accept', u'acceptable', u'acceptance', u'access', u'accessibility', u'accessible', u'accessing', u'accidental', u'accidents', u'accolades', u'accommodate', u'accompanying', u'accomplishments', u'accordance', u'accordingly', u'accords', u'account', u'accountability', u'accountable', u'accounting', u'accounts', u'accreditation', u'accreditors', u'accrual', u'accrued', u'accumulate', u'accumulated', u'accuracy', u'accurate', u'accused', u'accutane', u'acequia', u'achieve', u'achievement', u'achievements', u'achieving', u'aci', u'acid', u'acidification', u'acin', u'ackerman', u'acknowledge', u'acme', u'acorn', u'acosta', u'acquire', u'acquisition', u'acre', u'acre-feet', u'acres', u'across', u'across-the-board', u'act', u'acting', u'action']\n"
     ]
    }
   ],
   "source": [
    "word_list = favorite_words.columns.tolist()\n",
    "print \"Some of the words in it\", word_list[800:900]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "776\n"
     ]
    }
   ],
   "source": [
    "def word_finder(list,start):\n",
    "    for index, element in enumerate(list, start):\n",
    "        if element[0]!=\"a\":\n",
    "            pass\n",
    "        else:\n",
    "            first = index\n",
    "            break\n",
    "    return first\n",
    "x = word_list\n",
    "print word_finder(x,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'a'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_list[776]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Give words a count that is relevant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(min_df=1)\n",
    "vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Corpus\n",
    "I used the whole must repited words to have more of a global tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus = favorite_words.columns.tolist()\n",
    "X = vectorizer.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'economy', u'this']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[u'africans',\n",
       " u'after',\n",
       " u'aftermath',\n",
       " u'afternoon',\n",
       " u'afterschool',\n",
       " u'afterward',\n",
       " u'ag',\n",
       " u'again',\n",
       " u'against',\n",
       " u'agana']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyze = vectorizer.build_analyzer()\n",
    "print analyze(\"economy a this\")\n",
    "vectorizer.get_feature_names()[910:920]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4357"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.vocabulary_.get('document') #not seen in the training corpus will be completely ignored in future calls to the transform method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.transform(['Something completely unrelated']).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method for later analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def new_text_vector(string):\n",
    "    array = vectorizer.transform([string]).toarray()\n",
    "    return array\n",
    "new_text_vector(\"Some piece of text I want to classify for being as rejecting discrimination\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfTransformer(norm=u'l2', smooth_idf=True, sublinear_tf=False,\n",
       "         use_idf=True)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "transformer = TfidfTransformer()\n",
    "transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6.25227343,  4.93051759,  6.94542061, ...,  6.94542061,\n",
       "        6.5399555 ,  6.94542061])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf = transformer.fit_transform(favorite_words)\n",
    "tfidf_array = tfidf.toarray()\n",
    "tfidf_array.shape\n",
    "tfidf_array[20].max()\n",
    "transformer.idf_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13670\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(min_df=1)\n",
    "vectorizer.fit_transform(corpus)\n",
    "vec_idf = vectorizer.idf_\n",
    "print len(vec_idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,\n",
      "            ...\n",
      "            886, 887, 888, 889, 890, 891, 892, 893, 894, 896],\n",
      "           dtype='int64', length=763)\n",
      "Int64Index([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,\n",
      "            ...\n",
      "            886, 887, 888, 889, 890, 891, 892, 893, 894, 896],\n",
      "           dtype='int64', length=763)\n"
     ]
    }
   ],
   "source": [
    "words_weight = pd.DataFrame(tfidf_array, index=congress_words.index , columns=corpus)\n",
    "print congress_words.index\n",
    "print words_weight.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title_x</th>\n",
       "      <th>firstname</th>\n",
       "      <th>middlename</th>\n",
       "      <th>lastname</th>\n",
       "      <th>name_suffix</th>\n",
       "      <th>nickname</th>\n",
       "      <th>party_x</th>\n",
       "      <th>state_x</th>\n",
       "      <th>district_x</th>\n",
       "      <th>in_office</th>\n",
       "      <th>...</th>\n",
       "      <th>ziegler</th>\n",
       "      <th>zimbabwe</th>\n",
       "      <th>zimmer</th>\n",
       "      <th>zinc</th>\n",
       "      <th>zion</th>\n",
       "      <th>zoberman</th>\n",
       "      <th>zone</th>\n",
       "      <th>zones</th>\n",
       "      <th>zoo</th>\n",
       "      <th>zuni</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rep</td>\n",
       "      <td>Neil</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Abercrombie</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>D</td>\n",
       "      <td>HI</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rep</td>\n",
       "      <td>Gary</td>\n",
       "      <td>L.</td>\n",
       "      <td>Ackerman</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>D</td>\n",
       "      <td>NY</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rep</td>\n",
       "      <td>Robert</td>\n",
       "      <td>B.</td>\n",
       "      <td>Aderholt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>R</td>\n",
       "      <td>AL</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sen</td>\n",
       "      <td>Daniel</td>\n",
       "      <td>Kahikina</td>\n",
       "      <td>Akaka</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>D</td>\n",
       "      <td>HI</td>\n",
       "      <td>Junior Seat</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sen</td>\n",
       "      <td>Wayne</td>\n",
       "      <td>A.</td>\n",
       "      <td>Allard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>R</td>\n",
       "      <td>CO</td>\n",
       "      <td>Senior Seat</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 14450 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  title_x firstname middlename     lastname name_suffix nickname party_x  \\\n",
       "0     Rep      Neil        NaN  Abercrombie         NaN      NaN       D   \n",
       "1     Rep      Gary         L.     Ackerman         NaN      NaN       D   \n",
       "2     Rep    Robert         B.     Aderholt         NaN      NaN       R   \n",
       "3     Sen    Daniel   Kahikina        Akaka         NaN      NaN       D   \n",
       "4     Sen     Wayne         A.       Allard         NaN      NaN       R   \n",
       "\n",
       "  state_x   district_x  in_office  ...  ziegler zimbabwe zimmer zinc zion  \\\n",
       "0      HI            1          0  ...      0.0      0.0    0.0  0.0  0.0   \n",
       "1      NY            5          0  ...      0.0      0.0    0.0  0.0  0.0   \n",
       "2      AL            4          1  ...      0.0      0.0    0.0  0.0  0.0   \n",
       "3      HI  Junior Seat          0  ...      0.0      0.0    0.0  0.0  0.0   \n",
       "4      CO  Senior Seat          0  ...      0.0      0.0    0.0  0.0  0.0   \n",
       "\n",
       "  zoberman zone  zones  zoo  zuni  \n",
       "0      0.0  0.0    0.0  0.0   0.0  \n",
       "1      0.0  0.0    0.0  0.0   0.0  \n",
       "2      0.0  0.0    0.0  0.0   0.0  \n",
       "3      0.0  0.0    0.0  0.0   0.0  \n",
       "4      0.0  0.0    0.0  0.0   0.0  \n",
       "\n",
       "[5 rows x 14450 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "capitol_words = congress_words.merge(words_weight, right_index=True, left_index=True)\n",
    "capitol_words.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>a&amp;m</th>\n",
       "      <th>a-plus</th>\n",
       "      <th>a.</th>\n",
       "      <th>a.d.</th>\n",
       "      <th>a.m.</th>\n",
       "      <th>a.m.e.</th>\n",
       "      <th>aaa</th>\n",
       "      <th>aacute</th>\n",
       "      <th>aahsa</th>\n",
       "      <th>...</th>\n",
       "      <th>ziegler</th>\n",
       "      <th>zimbabwe</th>\n",
       "      <th>zimmer</th>\n",
       "      <th>zinc</th>\n",
       "      <th>zion</th>\n",
       "      <th>zoberman</th>\n",
       "      <th>zone</th>\n",
       "      <th>zones</th>\n",
       "      <th>zoo</th>\n",
       "      <th>zuni</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.096384</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 13644 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     a  a&m  a-plus   a.  a.d.      a.m.  a.m.e.  aaa  aacute  aahsa  ...   \\\n",
       "0  0.0  0.0     0.0  0.0   0.0  0.000000     0.0  0.0     0.0    0.0  ...    \n",
       "1  0.0  0.0     0.0  0.0   0.0  0.000000     0.0  0.0     0.0    0.0  ...    \n",
       "2  0.0  0.0     0.0  0.0   0.0  0.000000     0.0  0.0     0.0    0.0  ...    \n",
       "3  0.0  0.0     0.0  0.0   0.0  0.000000     0.0  0.0     0.0    0.0  ...    \n",
       "4  0.0  0.0     0.0  0.0   0.0  0.096384     0.0  0.0     0.0    0.0  ...    \n",
       "\n",
       "   ziegler  zimbabwe  zimmer  zinc  zion  zoberman  zone  zones  zoo  zuni  \n",
       "0      0.0       0.0     0.0   0.0   0.0       0.0   0.0    0.0  0.0   0.0  \n",
       "1      0.0       0.0     0.0   0.0   0.0       0.0   0.0    0.0  0.0   0.0  \n",
       "2      0.0       0.0     0.0   0.0   0.0       0.0   0.0    0.0  0.0   0.0  \n",
       "3      0.0       0.0     0.0   0.0   0.0       0.0   0.0    0.0  0.0   0.0  \n",
       "4      0.0       0.0     0.0   0.0   0.0       0.0   0.0    0.0  0.0   0.0  \n",
       "\n",
       "[5 rows x 13644 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_column_names_capitol = capitol_words.columns.tolist()[word_finder(capitol_words,0):]\n",
    "capitol_words[word_column_names_capitol].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.815564347877871"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "capitol_words[word_column_names_capitol].sum().max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting rid of the words that 95% of the people said\n",
    "Because they don't add much in to analyzing what makes legislators different from one another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([], dtype='object')"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_frequencies = (capitol_words[word_column_names_capitol]>0).astype(int).sum(axis=0).astype(float)/capitol_words.shape[0]\n",
    "most_frequent_words = word_frequencies[word_frequencies>.95].index\n",
    "most_frequent_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "323"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_frequencies = (capitol_words[word_column_names_capitol]>0).astype(int).sum(axis=0)\n",
    "word_frequencies.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entries before getting rid of independents: 763\n",
      "Entries after getting rid of independents: 760\n",
      "Number of independents: 3\n"
     ]
    }
   ],
   "source": [
    "capitol_words.party_x.unique()\n",
    "party_mask = capitol_words.party_x!=\"I\"\n",
    "two_party_words = capitol_words[party_mask]\n",
    "print \"Entries before getting rid of independents:\", capitol_words.shape[0]\n",
    "print \"Entries after getting rid of independents:\", two_party_words.shape[0]\n",
    "print \"Number of independents:\", (capitol_words.shape[0])-(two_party_words.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
