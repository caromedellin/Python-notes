{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning the Data and creating a sparce matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I start by importing the basic libraries and the data from a file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is what the data looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>firstname</th>\n",
       "      <th>middlename</th>\n",
       "      <th>lastname</th>\n",
       "      <th>name_suffix</th>\n",
       "      <th>nickname</th>\n",
       "      <th>party</th>\n",
       "      <th>state</th>\n",
       "      <th>district</th>\n",
       "      <th>in_office</th>\n",
       "      <th>...</th>\n",
       "      <th>govtrack_id</th>\n",
       "      <th>crp_id</th>\n",
       "      <th>twitter_id</th>\n",
       "      <th>congresspedia_url</th>\n",
       "      <th>youtube_url</th>\n",
       "      <th>facebook_id</th>\n",
       "      <th>official_rss</th>\n",
       "      <th>senate_class</th>\n",
       "      <th>birthdate</th>\n",
       "      <th>oc_email</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rep</td>\n",
       "      <td>Neil</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Abercrombie</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>D</td>\n",
       "      <td>HI</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>400001</td>\n",
       "      <td>N00007665</td>\n",
       "      <td>neilabercrombie</td>\n",
       "      <td>http://www.opencongress.org/wiki/Neil_Abercrombie</td>\n",
       "      <td>http://youtube.com/hawaiirep1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1938-06-26</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rep</td>\n",
       "      <td>Gary</td>\n",
       "      <td>L.</td>\n",
       "      <td>Ackerman</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>D</td>\n",
       "      <td>NY</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>400003</td>\n",
       "      <td>N00001143</td>\n",
       "      <td>repgaryackerman</td>\n",
       "      <td>http://www.opencongress.org/wiki/Gary_Ackerman</td>\n",
       "      <td>http://youtube.com/RepAckerman</td>\n",
       "      <td>RepAcherman</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1942-11-19</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rep</td>\n",
       "      <td>Robert</td>\n",
       "      <td>B.</td>\n",
       "      <td>Aderholt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>R</td>\n",
       "      <td>AL</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>400004</td>\n",
       "      <td>N00003028</td>\n",
       "      <td>Robert_Aderholt</td>\n",
       "      <td>http://www.opencongress.org/wiki/Robert_Aderholt</td>\n",
       "      <td>http://youtube.com/RobertAderholt</td>\n",
       "      <td>19787529402</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1965-07-22</td>\n",
       "      <td>Rep.Aderholt@opencongress.org</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sen</td>\n",
       "      <td>Daniel</td>\n",
       "      <td>Kahikina</td>\n",
       "      <td>Akaka</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>D</td>\n",
       "      <td>HI</td>\n",
       "      <td>Junior Seat</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>300001</td>\n",
       "      <td>N00007653</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www.opencongress.org/wiki/Daniel_Akaka</td>\n",
       "      <td>http://youtube.com/senatorakaka</td>\n",
       "      <td>danielakaka</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I</td>\n",
       "      <td>1924-09-11</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sen</td>\n",
       "      <td>Wayne</td>\n",
       "      <td>A.</td>\n",
       "      <td>Allard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>R</td>\n",
       "      <td>CO</td>\n",
       "      <td>Senior Seat</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>300003</td>\n",
       "      <td>N00009082</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www.opencongress.org/wiki/Wayne_Allard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>II</td>\n",
       "      <td>1943-12-02</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  title firstname middlename     lastname name_suffix nickname party state  \\\n",
       "0   Rep      Neil        NaN  Abercrombie         NaN      NaN     D    HI   \n",
       "1   Rep      Gary         L.     Ackerman         NaN      NaN     D    NY   \n",
       "2   Rep    Robert         B.     Aderholt         NaN      NaN     R    AL   \n",
       "3   Sen    Daniel   Kahikina        Akaka         NaN      NaN     D    HI   \n",
       "4   Sen     Wayne         A.       Allard         NaN      NaN     R    CO   \n",
       "\n",
       "      district  in_office              ...               govtrack_id  \\\n",
       "0            1          0              ...                    400001   \n",
       "1            5          0              ...                    400003   \n",
       "2            4          1              ...                    400004   \n",
       "3  Junior Seat          0              ...                    300001   \n",
       "4  Senior Seat          0              ...                    300003   \n",
       "\n",
       "      crp_id       twitter_id  \\\n",
       "0  N00007665  neilabercrombie   \n",
       "1  N00001143  repgaryackerman   \n",
       "2  N00003028  Robert_Aderholt   \n",
       "3  N00007653              NaN   \n",
       "4  N00009082              NaN   \n",
       "\n",
       "                                   congresspedia_url  \\\n",
       "0  http://www.opencongress.org/wiki/Neil_Abercrombie   \n",
       "1     http://www.opencongress.org/wiki/Gary_Ackerman   \n",
       "2   http://www.opencongress.org/wiki/Robert_Aderholt   \n",
       "3      http://www.opencongress.org/wiki/Daniel_Akaka   \n",
       "4      http://www.opencongress.org/wiki/Wayne_Allard   \n",
       "\n",
       "                         youtube_url  facebook_id official_rss  senate_class  \\\n",
       "0      http://youtube.com/hawaiirep1          NaN          NaN           NaN   \n",
       "1     http://youtube.com/RepAckerman  RepAcherman          NaN           NaN   \n",
       "2  http://youtube.com/RobertAderholt  19787529402          NaN           NaN   \n",
       "3    http://youtube.com/senatorakaka  danielakaka          NaN             I   \n",
       "4                                NaN          NaN          NaN            II   \n",
       "\n",
       "    birthdate                       oc_email  \n",
       "0  1938-06-26                            NaN  \n",
       "1  1942-11-19                            NaN  \n",
       "2  1965-07-22  Rep.Aderholt@opencongress.org  \n",
       "3  1924-09-11                            NaN  \n",
       "4  1943-12-02                            NaN  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "legislatorsData = pd.read_csv(\"../data/legislators.csv\")\n",
    "legislatorsData.head()\n",
    "legislatorsData.columns\n",
    "legislators = pd.DataFrame(legislatorsData)\n",
    "legislators.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from urllib2 import Request, urlopen\n",
    "import json\n",
    "from pandas.io.json import json_normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def requestWords( id ):\n",
    "    id = str(id)\n",
    "    url = \"http://capitolwords.org/api/1/phrases.json?entity_type=legislator&entity_value=\"+id+\"&apikey=0bf8e7eb6ce146f48217bfee767c998d\"\n",
    "    request=Request(url)\n",
    "    response = urlopen(request)\n",
    "    contents = response.read()\n",
    "    len(contents)\n",
    "    if len(contents) > 2:\n",
    "        data = json.loads(contents)\n",
    "        words = json_normalize(data)\n",
    "        list_of_words = words.ngram.tolist()\n",
    "        string_of_words =\"|\".join(list_of_words)\n",
    "        return string_of_words\n",
    "    else:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "legislators['favorite_words'] = legislators.apply(lambda row: requestWords(row['bioguide_id']),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    hawaiian|hawaii|hawaiians|hawaii's|kalaupapa|e...\n",
      "1    queens|rabbi|jewish|bayside|flushing|nassau|br...\n",
      "2    aderholt|requesting|irons|huntsville|alabama|r...\n",
      "Name: favorite_words, dtype: object\n",
      "All entries before getting rid of entris with no words: 897\n"
     ]
    }
   ],
   "source": [
    "print legislators.favorite_words.head(3)\n",
    "print \"All entries before getting rid of entris with no words:\", len(legislators.favorite_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "legislators_words = legislators[legislators.favorite_words.notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of legislators with word record: 763\n"
     ]
    }
   ],
   "source": [
    "print \"Number of legislators with word record:\", len(legislators_words.favorite_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "favorite_words = legislators_words.favorite_words.str.get_dummies(sep = \"|\")\n",
    "print favorite_words.head(3)\n",
    "favorite_words.columns[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "favorite_words.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "favorite_words.columns[260:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "favorite_words.columns[760:800]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(min_df=1)\n",
    "vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Corpus\n",
    "I used the whole must repited words to have more of a global tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corpus = favorite_words.columns.tolist()\n",
    "corpus[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = vectorizer.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "analyze = vectorizer.build_analyzer()\n",
    "print analyze(\"economy a this\")\n",
    "vectorizer.get_feature_names()[910:920]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vectorizer.vocabulary_.get('document') #not seen in the training corpus will be completely ignored in future calls to the transform method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vectorizer.transform(['Something completely unrelated']).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Biagram\n",
    "not sure if i shoud add Biagrams since the corpus is made up single words and a lot of of number dropping politicians love to do."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "transformer = TfidfTransformer()\n",
    "transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tfidf = transformer.fit_transform(favorite_words)\n",
    "tfidf_array = tfidf.toarray()\n",
    "tfidf_array.shape\n",
    "tfidf_array[20].max()\n",
    "transformer.idf_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(min_df=1)\n",
    "vectorizer.fit_transform(corpus)\n",
    "vec_idf = vectorizer.idf_\n",
    "print len(vec_idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "words_weight = pd.DataFrame(tfidf_array, index=legislators_words.index , columns=corpus)\n",
    "print legislators_words.index\n",
    "print words_weight.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "capitol_words = legislators_words.merge(words_weight, right_index=True, left_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "capitol_words.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "del capitol_words[\"a\"]\n",
    "column_names_capitol = capitol_words.columns.tolist()\n",
    "word_column_names = column_names_capitol[806:]\n",
    "number_column_names = column_names_capitol[30:805]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "capitol_words[word_column_names].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "capitol_words[word_column_names].sum().max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now I will make another DataFrame removing the words with the max counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "total_word_counts = capitol_words[word_column_names].sum()\n",
    "max_sum_col = total_word_counts[total_word_counts==total_word_counts.max()]\n",
    "max_sum_col.index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"Words before cleanse for maximizing variance:\", len(word_column_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting rid of the words that 95% of the people said\n",
    "Because they don't add much in to analyzing what makes legislators different from one another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def percentage_global_mention(word_column_names):\n",
    "    for word in word_column_names:\n",
    "        not_mentioned_mask = capitol_words[word_column_names][word]==0.0\n",
    "        not_mentioned_count = capitol_words[word_column_names][word].mask(not_mentioned_mask).count()\n",
    "        index_count = capitol_words.count()[0]\n",
    "        percentage = float(not_mentioned_count)/index_count\n",
    "        if percentage > 0.95:\n",
    "            print percentage , word\n",
    "            del capitol_words[word]\n",
    "        else:\n",
    "            print \"Nothing to worry about\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Or a better way to do it:\n",
    "credits to Sergey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "word_frequencies = (capitol_words[word_column_names]>0).astype(int).sum(axis=0).astype(float)/capitol_words.shape[0]\n",
    "most_frequent_words = word_frequencies[word_frequencies>.95].index\n",
    "most_frequent_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word_frequencies = (capitol_words[word_column_names]>0).astype(int).sum(axis=0)\n",
    "word_frequencies.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "capitol_words.party_x.unique()\n",
    "party_mask = capitol_words.party_x!=\"I\"\n",
    "two_party_words = capitol_words[party_mask]\n",
    "print \"Entries before getting rid of independents:\", capitol_words.shape[0]\n",
    "print \"Entries after getting rid of independents:\", two_party_words.shape[0]\n",
    "print \"Number of independents:\", (capitol_words.shape[0])-(two_party_words.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "two_party_words.to_csv(path_or_buf=\"../data/two.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
